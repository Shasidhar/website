<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/">
	<channel>
		<title>Shashidhar</title>
		<description>Blog and website of Shashidhar, blogging mainly for tech. Opinions expressed are mine.</description>
		<link>https://shasidhare.com</link>
		<atom:link href="https://shasidhare.com/feed.xml" rel="self" type="application/rss+xml" />
		
			<item>
				<title>Apache Spark Performance Tuning</title>
				
				
					<description>&lt;p&gt;As we all know Apache Spark is the  most popular framework now a days for Big Data solutions, in this blog we will try to analyse different key factors that can be used to improve the performance of Spark applications in production.&lt;/p&gt;

</description>
				
				<pubDate>Tue, 03 Nov 2015 02:02:27 +0530</pubDate>
				<link>https://shasidhare.com/spark/2015/11/03/apache-spark-performance-tuning.html</link>
				<guid isPermaLink="true">https://shasidhare.com/spark/2015/11/03/apache-spark-performance-tuning.html</guid>
			</item>
		
			<item>
				<title>Machine Learning in Spark</title>
				
				
					<description>&lt;p&gt;In software industry with adoption of Hadoop, data scientists are in high demand. There is a well known fact that people from data science background always face difficulty to apply data science on bigdata due to lack of bigdata knowledge and people from programming background face the same when they try data science on bigdata due to lack of data science knowledge. Here we are seeing two different set of people whose end goal &lt;strong&gt;Machine Learning on Big Data&lt;/strong&gt; appears similar. So we try to solve this and give you the correct steps to get started in this regard.&lt;/p&gt;

</description>
				
				<pubDate>Sat, 31 Oct 2015 02:02:27 +0530</pubDate>
				<link>https://shasidhare.com/spark/2015/10/31/machine-learning-in-spark.html</link>
				<guid isPermaLink="true">https://shasidhare.com/spark/2015/10/31/machine-learning-in-spark.html</guid>
			</item>
		
			<item>
				<title>Zookeeper - Dynamic Configuration Source with Archaius</title>
				
				
					<description>&lt;p&gt;Dynamic configuration is the ability to change the configuration while system is running. Archaius is the configuration management library which can retrieve properties from several sources and load them into the system dynamically.For a distributed system Apache Zookeeper is the default coordination service. This blog shows&lt;/p&gt;

</description>
				
				<pubDate>Tue, 27 Oct 2015 02:02:27 +0530</pubDate>
				<link>https://shasidhare.com/zookeeper/2015/10/27/distributed-configuration-management-with-zookeeper.html</link>
				<guid isPermaLink="true">https://shasidhare.com/zookeeper/2015/10/27/distributed-configuration-management-with-zookeeper.html</guid>
			</item>
		
			<item>
				<title>Understanding Mapreduce idea</title>
				
				
					<description>&lt;p&gt;In my previous blog we have seen about the concept of Map reduce. This blog illustrates how the idea of Mapreduce can be achieved in simple java programs and then we take a step ahead to understand how it is implemented in hadoop. It lays out the different components of hadoop Mapreduce implementation for better understanding. Now, let’s go further and understand the idea of Map reduce by writing simple java program and analyse the solution.&lt;/p&gt;

</description>
				
				<pubDate>Sat, 31 Jan 2015 02:02:27 +0530</pubDate>
				<link>https://shasidhare.com/hadoop/2015/01/31/understanding-mapreduce-idea-.html</link>
				<guid isPermaLink="true">https://shasidhare.com/hadoop/2015/01/31/understanding-mapreduce-idea-.html</guid>
			</item>
		
			<item>
				<title>Mapreduce History</title>
				
				
					<description>&lt;p&gt;In this blog, lets look into the roots of Map Reduce idea. From where does the idea of Map-Reduce came and some background history about it.&lt;/p&gt;

</description>
				
				<pubDate>Sat, 31 Jan 2015 02:02:27 +0530</pubDate>
				<link>https://shasidhare.com/hadoop/2015/01/31/map%20reduce-history.html</link>
				<guid isPermaLink="true">https://shasidhare.com/hadoop/2015/01/31/map%20reduce-history.html</guid>
			</item>
		
			<item>
				<title>Secondary Sorting in Hadoop</title>
				
				
					<description>&lt;p&gt;I have read many blog’s about secondary sorting when I was learning hadoop. Most of these blogs tries to explain it conceptually which is not sufficient as it is kind of hack in hadoop. In this blog let’s see how that can be understood in a better way .We see how data changes internally in each step of secondary sort.&lt;/p&gt;

</description>
				
				<pubDate>Fri, 30 Jan 2015 02:02:27 +0530</pubDate>
				<link>https://shasidhare.com/hadoop/2015/01/30/secondary-sorting--in-hadoop.html</link>
				<guid isPermaLink="true">https://shasidhare.com/hadoop/2015/01/30/secondary-sorting--in-hadoop.html</guid>
			</item>
		
			<item>
				<title>Hadoop history</title>
				
				
					<description>&lt;p&gt;Apache Hadoop is an open source software project that enables distributed processing of large data sets across clusters of commodity servers. It is designed to scale up from a single server to thousands of machines, with a very high degree of fault tolerance.&lt;/p&gt;

</description>
				
				<pubDate>Fri, 30 Jan 2015 02:02:27 +0530</pubDate>
				<link>https://shasidhare.com/hadoop/2015/01/30/hadoop-history.html</link>
				<guid isPermaLink="true">https://shasidhare.com/hadoop/2015/01/30/hadoop-history.html</guid>
			</item>
		
	</channel>
</rss>
